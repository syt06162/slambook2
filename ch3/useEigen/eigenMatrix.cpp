#include <iostream>

using namespace std;

#include <ctime>
// Eigen core part
#include <Eigen/Core>
// Algebraic operations on dense matrices (inverse, eigenvalues, etc.)
#include <Eigen/Dense>

using namespace Eigen;

#define MATRIX_SIZE 50

/****************************
* This program demonstrates the basic usage of Eigen's basic types
****************************/

int main(int argc, char** argv) {
    // In Eigen, all vectors and matrices are Eigen::Matrix, which is a template class.
    // Its first three parameters are: data type, rows, columns
    // Declare a 2*3 float matrix
    Matrix<float, 2, 3> matrix_23;

    // Similarly, Eigen provides many built-in types through typedef, but the underlying type is still Eigen::Matrix.
    // For example, Vector3d is essentially Eigen::Matrix<double, 3, 1>, i.e., a three-dimensional vector.
    Vector3d v_3d;
    // This is the same as above
    Matrix<float, 3, 1> vd_3d;

    // Matrix3d is essentially Eigen::Matrix<double, 3, 3>
    Matrix3d matrix_33 = Matrix3d::Zero(); // initialized to zero
    // If the matrix size is uncertain, you can use dynamically sized matrices
    Matrix<double, Dynamic, Dynamic> matrix_dynamic;
    // Simpler
    MatrixXd matrix_x;
    // There are many other types like this, which we won't list one by one

    // Below are operations on Eigen matrices
    // Input data (initialization)
    matrix_23 << 1, 2, 3, 4, 5, 6;
    // Output
    cout << "matrix 2x3 from 1 to 6: \n" << matrix_23 << endl;

    // Access elements of the matrix using ()
    cout << "print matrix 2x3: " << endl;
    for (int i = 0; i < 2; i++) {
        for (int j = 0; j < 3; j++) cout << matrix_23(i, j) << "\t";
        cout << endl;
    }

    // Matrix-vector multiplication (actually still matrix-matrix multiplication)
    v_3d << 3, 2, 1;
    vd_3d << 4, 5, 6;

    // But in Eigen, you can't mix two different types of matrices like this
    // Matrix<double, 2, 1> result_wrong_type = matrix_23 * v_3d;
    // It should be explicitly cast
    Matrix<double, 2, 1> result = matrix_23.cast<double>() * v_3d;
    cout << "[1,2,3;4,5,6]*[3,2,1]=" << result.transpose() << endl;

    Matrix<float, 2, 1> result2 = matrix_23 * vd_3d;
    cout << "[1,2,3;4,5,6]*[4,5,6]: " << result2.transpose() << endl;

    // Similarly, you can't get the dimensions of the matrix wrong
    // Try uncommenting the following line to see what error Eigen reports
    // Eigen::Matrix<double, 2, 3> result_wrong_dimension = matrix_23.cast<double>() * v_3d;

    // Some matrix operations
    // Arithmetic operations are not demonstrated here, you can directly use +-*/.
    matrix_33 = Matrix3d::Random();      // Random matrix
    cout << "random matrix: \n" << matrix_33 << endl;
    cout << "transpose: \n" << matrix_33.transpose() << endl;      // Transpose
    cout << "sum: " << matrix_33.sum() << endl;            // Sum of elements
    cout << "trace: " << matrix_33.trace() << endl;          // Trace
    cout << "times 10: \n" << 10 * matrix_33 << endl;               // Scalar multiplication
    cout << "inverse: \n" << matrix_33.inverse() << endl;        // Inverse
    cout << "det: " << matrix_33.determinant() << endl;    // Determinant

    // Eigenvalues
    // Diagonalization is guaranteed for real symmetric matrices
    SelfAdjointEigenSolver<Matrix3d> eigen_solver(matrix_33.transpose() * matrix_33);
    cout << "Eigen values = \n" << eigen_solver.eigenvalues() << endl;
    cout << "Eigen vectors = \n" << eigen_solver.eigenvectors() << endl;

    // Solving equations
    // We solve the equation matrix_NN * x = v_Nd
    // The size of N is defined in the macro above, generated by random numbers
    // Directly taking the inverse is the most straightforward, but it involves a large computational cost

    Matrix<double, MATRIX_SIZE, MATRIX_SIZE> matrix_NN
        = MatrixXd::Random(MATRIX_SIZE, MATRIX_SIZE);
    matrix_NN = matrix_NN * matrix_NN.transpose();  // Ensure semi-positive definite
    Matrix<double, MATRIX_SIZE, 1> v_Nd = MatrixXd::Random(MATRIX_SIZE, 1);

    clock_t time_stt = clock(); // Timer
    // Direct inverse
    Matrix<double, MATRIX_SIZE, 1> x = matrix_NN.inverse() * v_Nd;
    cout << "time of normal inverse is "
        << 1000 * (clock() - time_stt) / (double)CLOCKS_PER_SEC << "ms" << endl;
    cout << "x = " << x.transpose() << endl;

    // Usually, matrix decomposition is used for solving equations, such as QR decomposition, which is much faster
    time_stt = clock();
    x = matrix_NN.colPivHouseholderQr().solve(v_Nd);
    cout << "time of QR decomposition is "
        << 1000 * (clock() - time_stt) / (double)CLOCKS_PER_SEC << "ms" << endl;
    cout << "x = " << x.transpose() << endl;

    // For positive definite matrices, you can also use Cholesky decomposition to solve equations
    time_stt = clock();
    x = matrix_NN.ldlt().solve(v_Nd);
    cout << "time of LDLT decomposition is "
        << 1000 * (clock() - time_stt) / (double)CLOCKS_PER_SEC << "ms" << endl;
    cout << "x = " << x.transpose() << endl;

    return 0;
}
